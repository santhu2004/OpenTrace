# ğŸš€ Hybrid Python/Go Architecture

## Overview

This project implements a **hybrid architecture** that combines the best of both Python and Go:

- **ğŸ Python**: Threat intelligence, tagging, parsing, Tor integration, GUI/CLI
- **âš¡ Go**: High-performance web crawling, concurrent processing, link discovery

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Python Controller                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Parser    â”‚  â”‚  Detector   â”‚  â”‚   Tagger    â”‚         â”‚
â”‚  â”‚ (Beautiful  â”‚  â”‚ (Site Type) â”‚  â”‚ (Threat     â”‚         â”‚
â”‚  â”‚   Soup)     â”‚  â”‚             â”‚  â”‚  Intel)     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚           â”‚              â”‚              â”‚                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                          â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Subprocess Call                        â”‚   â”‚
â”‚  â”‚  ./fastcrawl.exe -input config.json -output resultsâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Go Crawler                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Fetcher   â”‚  â”‚   Crawler   â”‚  â”‚   Types     â”‚         â”‚
â”‚  â”‚ (HTTP/HTTPS)â”‚  â”‚(Concurrent) â”‚  â”‚ (JSON I/O)  â”‚         â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚           â”‚              â”‚              â”‚                  â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                          â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              JSON Output                            â”‚   â”‚
â”‚  â”‚  {"results": [...], "summary": {...}}              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
CR4WL3R/
â”œâ”€â”€ threat_crawler/
â”‚   â”œâ”€â”€ main.py                    # Python entry point
â”‚   â”œâ”€â”€ core/                      # Python threat intelligence
â”‚   â”‚   â”œâ”€â”€ crawler.py            # Python crawler (legacy)
â”‚   â”‚   â”œâ”€â”€ parser.py             # HTML parsing
â”‚   â”‚   â”œâ”€â”€ detector.py           # Site type detection
â”‚   â”‚   â””â”€â”€ tagger.py             # Threat tagging
â”‚   â”œâ”€â”€ fetcher/                   # Python HTTP client
â”‚   â”‚   â””â”€â”€ client.py             # Tor integration
â”‚   â”œâ”€â”€ go_crawler/               # ğŸ†• Go crawler module
â”‚   â”‚   â”œâ”€â”€ main.go               # Go entry point
â”‚   â”‚   â”œâ”€â”€ types.go              # Data structures
â”‚   â”‚   â”œâ”€â”€ fetcher.go            # HTTP client
â”‚   â”‚   â”œâ”€â”€ crawler.go            # Core crawling logic
â”‚   â”‚   â”œâ”€â”€ fastcrawl.exe         # Compiled binary
â”‚   â”‚   â”œâ”€â”€ example_input.json    # Example config
â”‚   â”‚   â””â”€â”€ README.md             # Go module docs
â”‚   â”œâ”€â”€ go_integration_example.py # ğŸ†• Integration example
â”‚   â””â”€â”€ HYBRID_ARCHITECTURE.md    # This file
â””â”€â”€ README.md                     # Main project docs
```

## ğŸš€ Quick Start

### 1. Build the Go Crawler

```bash
cd threat_crawler/go_crawler
go build -o fastcrawl.exe .
```

### 2. Test the Go Crawler

```bash
# Test with example configuration
.\fastcrawl.exe -input example_input.json -output test_results.json

# Test with stdin
echo '{"target_url": "https://httpbin.org", "max_depth": 1}' | .\fastcrawl.exe
```

### 3. Run the Integration Example

```bash
cd threat_crawler
python go_integration_example.py
```

## ğŸ“‹ Configuration

### Go Crawler Input JSON

```json
{
  "target_url": "https://example.com",
  "max_depth": 3,
  "max_links": 100,
  "timeout": "30s",
  "max_concurrency": 10,
  "user_agent": "ThreatCrawler/1.0",
  "respect_robots": false
}
```

### Go Crawler Output JSON

```json
{
  "config": { /* Input configuration */ },
  "results": [
    {
      "url": "https://example.com",
      "status": 200,
      "title": "Example Page",
      "depth": 0,
      "discovered": "2024-01-01T12:00:00Z",
      "headers": { /* Response headers */ },
      "links": [ /* All links found */ ],
      "internal_links": [ /* Same-domain links */ ],
      "external_links": [ /* Cross-domain links */ ]
    }
  ],
  "summary": {
    "total_pages": 10,
    "successful": 8,
    "failed": 2,
    "internal_links": 25,
    "external_links": 15,
    "max_depth_reached": 2,
    "duration": "5000000000"
  },
  "timestamp": "2024-01-01T12:00:05Z"
}
```

## ğŸ”§ Python Integration

### Basic Integration

```python
import subprocess
import json

def call_go_crawler(config):
    """Call the Go crawler with configuration."""
    # Write config to file
    with open("crawl_config.json", "w") as f:
        json.dump(config, f)
    
    # Call Go binary
    result = subprocess.run([
        "./go_crawler/fastcrawl.exe",
        "-input", "crawl_config.json",
        "-output", "crawl_results.json"
    ], capture_output=True, text=True)
    
    # Read results
    with open("crawl_results.json", "r") as f:
        return json.load(f)

# Usage
config = {
    "target_url": "https://example.com",
    "max_depth": 2,
    "max_links": 50
}

results = call_go_crawler(config)
print(f"Crawled {results['summary']['total_pages']} pages")
```

### Advanced Integration with Threat Intelligence

```python
from core.parser import extract_page_info
from core.detector import detect_site_type
from core.tagger import tag_content

def enhance_go_results(go_results):
    """Apply Python threat intelligence to Go results."""
    enhanced = []
    
    for result in go_results['results']:
        # Apply your existing Python modules
        title, tech_stack = extract_page_info(result['html'])  # You'd need HTML content
        site_type = detect_site_type(result['html'])
        tags = tag_content(result['html'], result['headers'], tech_stack)
        
        enhanced_result = {
            "url": result["url"],
            "status_code": result["status"],
            "type": site_type,
            "title": title,
            "tech_stack": tech_stack,
            "headers": result["headers"],
            "tags": tags,
            "depth": result["depth"],
            "internal_links": result["internal_links"],
            "external_links": result["external_links"]
        }
        enhanced.append(enhanced_result)
    
    return enhanced
```

## âš¡ Performance Comparison

| Metric | Python Crawler | Go Crawler | Improvement |
|--------|----------------|------------|-------------|
| **Speed** | 10-50 pages/sec | 100-500 pages/sec | **10x faster** |
| **Memory** | ~200MB/1000 pages | ~50MB/1000 pages | **4x less** |
| **Concurrency** | Async (limited) | Goroutines (unlimited) | **Much better** |
| **CPU Usage** | Higher | Lower | **More efficient** |

## ğŸ¯ Use Cases

### When to Use Go Crawler
- **Large-scale crawling** (1000+ pages)
- **Performance-critical operations**
- **High-concurrency requirements**
- **Resource-constrained environments**

### When to Use Python Crawler
- **Small-scale testing**
- **Tor integration needed**
- **Complex threat intelligence**
- **Rapid prototyping**

### Hybrid Approach (Recommended)
- **Go**: Handle the heavy crawling
- **Python**: Apply threat intelligence
- **Best of both worlds**

## ğŸ”„ Migration Path

### Phase 1: Parallel Development
- Keep existing Python crawler
- Develop and test Go crawler
- Compare performance and results

### Phase 2: Integration
- Implement Python integration layer
- Test hybrid approach
- Validate threat intelligence accuracy

### Phase 3: Optimization
- Fine-tune Go crawler performance
- Optimize Python integration
- Add advanced features

### Phase 4: Production
- Deploy hybrid system
- Monitor performance
- Iterate and improve

## ğŸ› ï¸ Development

### Adding Features to Go Crawler

1. **New Configuration Options**
   ```go
   // In types.go
   type CrawlConfig struct {
       // ... existing fields
       NewFeature string `json:"new_feature"`
   }
   ```

2. **New Result Fields**
   ```go
   // In types.go
   type CrawlResult struct {
       // ... existing fields
       NewField string `json:"new_field"`
   }
   ```

3. **Implementation**
   ```go
   // In fetcher.go or crawler.go
   func (f *Fetcher) FetchPage(ctx context.Context, url string) (*CrawlResult, error) {
       // ... existing code
       result.NewField = "new value"
       return result, nil
   }
   ```

### Testing

```bash
# Test Go crawler
cd threat_crawler/go_crawler
go test ./...

# Test integration
cd threat_crawler
python go_integration_example.py

# Performance test
time ./fastcrawl.exe -input perf_test.json
```

## ğŸ”’ Security Considerations

### Rate Limiting
- Go crawler respects `max_concurrency`
- Configurable timeouts prevent overwhelming targets
- User agent identifies as security research tool

### Error Handling
- Graceful degradation on failures
- Comprehensive logging for debugging
- No sensitive data in error messages

### Legal Compliance
- Respect robots.txt (configurable)
- Configurable user agent
- Rate limiting to be respectful

## ğŸš€ Future Enhancements

### Go Crawler
- [ ] Robots.txt parsing
- [ ] Sitemap.xml support
- [ ] Cookie/session handling
- [ ] Proxy support
- [ ] Rate limiting per domain
- [ ] Result streaming
- [ ] Metrics collection

### Python Integration
- [ ] Real-time result processing
- [ ] Database integration
- [ ] Advanced threat intelligence
- [ ] Machine learning integration
- [ ] API endpoints

### Infrastructure
- [ ] Docker containers
- [ ] Kubernetes deployment
- [ ] Redis for distributed crawling
- [ ] PostgreSQL for result storage
- [ ] Prometheus metrics

## ğŸ“š Resources

- [Go HTTP Client Documentation](https://golang.org/pkg/net/http/)
- [Go Concurrency Patterns](https://golang.org/doc/effective_go.html#concurrency)
- [Python Subprocess Documentation](https://docs.python.org/3/library/subprocess.html)
- [JSON Schema Validation](https://json-schema.org/)

---

**ğŸ¯ The hybrid architecture gives you the performance of Go with the flexibility of Python, creating a powerful threat intelligence platform!** 