# üï∑Ô∏è CR4WL3R - Threat Intelligence Web Crawler

A sophisticated autonomous web crawler designed for threat intelligence gathering and dark web monitoring.

## üéØ Features

- **üï∏Ô∏è Autonomous Crawling**: Breadth-first search with configurable depth limits
- **üåê Tor Integration**: Automatic .onion site detection and Tor routing
- **üîç Threat Intelligence**: Content analysis and threat tagging
- **üìä Structured Output**: JSON-based results with metadata extraction
- **‚ö° Async Performance**: High-performance asynchronous crawling
- **üõ°Ô∏è Smart Filtering**: Domain-scoped crawling with external link discovery

## üöÄ Quick Start

### Prerequisites
```bash
# Python 3.8+
python --version

# Install dependencies
pip install -r threat_crawler/requirements.txt
```

### Basic Usage
```bash
cd threat_crawler
python main.py
```

### Configuration
Edit `threat_crawler/config/settings.py`:
```python
SEED_URL = "https://example.com"  # Your target URL
CRAWL_DEPTH_LIMIT = 3             # How deep to crawl
MAX_PAGES_PER_DOMAIN = 50         # Max pages per domain
```

## üìÅ Project Structure

```
CR4WL3R/
‚îú‚îÄ‚îÄ threat_crawler/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py      # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawler.py       # Main crawling logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parser.py        # HTML parsing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detector.py      # Site type detection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tagger.py        # Threat tagging
‚îÇ   ‚îú‚îÄ‚îÄ fetcher/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ client.py        # HTTP client (Tor support)
‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ writer.py        # JSON result storage
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ link_utils.py    # Link extraction
‚îÇ       ‚îî‚îÄ‚îÄ logger.py        # Logging utilities
‚îú‚îÄ‚îÄ venv/                    # Virtual environment
‚îú‚îÄ‚îÄ .gitignore              # Git ignore rules
‚îî‚îÄ‚îÄ README.md               # This file
```

## üîß Configuration

### Tor Setup (Optional)
For .onion site crawling:
1. Install Tor Browser or Tor service
2. Ensure Tor is running on `127.0.0.1:9050`
3. The crawler automatically detects .onion URLs

### Target Types
- **Regular Sites**: `https://example.com`
- **Onion Sites**: `http://example.onion`
- **Mixed Crawling**: Configure multiple seed URLs

## üìä Output Format

Results are saved to `output/results.json`:
```json
[
  {
    "url": "https://example.com",
    "status_code": 200,
    "type": "Forum",
    "title": "Example Forum",
    "tech_stack": ["WordPress", "JavaScript"],
    "headers": {},
    "tags": ["chat_forum", "exploit_market"]
  }
]
```

## üõ°Ô∏è Threat Intelligence

The crawler automatically tags content for:
- **Carding**: Credit card fraud indicators
- **Credentials**: Password/username dumps
- **Exploit Markets**: Malware/exploit sales
- **PII Leaks**: Personal information exposure
- **Chat Forums**: Underground communication platforms

## ‚ö†Ô∏è Legal & Ethical Considerations

- **Authorized Use Only**: Only crawl sites you own or have permission to crawl
- **Rate Limiting**: Respect robots.txt and implement delays
- **Data Privacy**: Handle sensitive data responsibly
- **Compliance**: Follow local laws and regulations

## üîÑ Development

### Adding New Threat Tags
Edit `threat_crawler/core/tagger.py`:
```python
def tag_content(html: str, headers: dict, tech_stack: list) -> list:
    tags = []
    # Add your custom detection logic
    if "your_keyword" in html.lower():
        tags.append("your_tag")
    return tags
```

### Extending Site Detection
Edit `threat_crawler/core/detector.py`:
```python
def detect_site_type(html):
    html_lower = html.lower()
    if "your_indicator" in html_lower:
        return "Your Site Type"
    return "Unknown"
```

## üìù License

This project is for educational and authorized security research purposes only.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

---

**‚ö†Ô∏è Disclaimer**: This tool is designed for legitimate security research and threat intelligence gathering. Users are responsible for ensuring compliance with applicable laws and regulations. 